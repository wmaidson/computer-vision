{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough transform\n",
    "\n",
    "The purpose of this class is:\n",
    "\n",
    "1. Understand the concept of the hough transform.\n",
    "2. How to use it to detect lines in an image.\n",
    "\n",
    "\n",
    "\n",
    "# Theory\n",
    "\n",
    "Hough Transform is a popular technique for detecting any shape, if you can represent that shape in mathematical form. It can detect the shape even if it is broken or distorted a little. Let's see how it works for a line.\n",
    "\n",
    "A line can be represented as y = mx + c or in parametric form, as $ \\rho = x \\cos \\theta + y \\sin \\theta $ Where $\\rho$ is the perpendicular distance from the origin to the line, and $ \\theta $ is the angle formed by this perpendicular line and the horizontal axis measured counterclockwise (this direction varies depending on the coordinate system representation. This representation is used in OpenCV). Check out the image below:\n",
    "\n",
    "![alt text](https://docs.opencv.org/3.0-beta/_images/houghlines1.svg \"Logo Title Text 1\")\n",
    "\n",
    "[logo]: https://docs.opencv.org/3.0-beta/_images/houghlines1.svg \"Logo Title Text 2\"\n",
    "\n",
    "\n",
    "Therefore, if the line is passing below the origin, it will have a positive rho and angle less than 180. If it is above the origin, instead of having an angle greater than 180, the angle will be less than 180 and rho will be considered negative. Any vertical lines will be 0 degrees and horizontal lines will be 90 degrees.\n",
    "\n",
    "Now let's see how Hough Transform works for lines. Any line can be represented in these two terms, ($\\rho, \\theta$) . So first it creates a 2D array or an accumulator (to hold values ​​of two parameters) and it is set to 0 initially. Leaving rows denote $\\rho$ and columns denote $\\theta$ . The size of the array depends on the precision you need. Suppose you want the angle accuracy to be 1 degree, you need 180 columns. For $\\rho$ , the maximum possible distance is the diagonal length of the image. So, given pixel precision, the number of lines can be the diagonal length of the image.\n",
    "\n",
    "Consider a 100x100 image with a horizontal line in the middle. Take the first point of the line. You know your (x, y) values. Now in the equation of the line, put the values ​​\\ theta = 0.1,2, ...., 180 and check what $\\rho$ you get. For each ($\\rho, \\theta$) even, you increment the value by one in our accumulator in its corresponding ($\\rho, \\theta$) cells So now in the accumulator, the cell (50.90) = 1 together with some other cells.\n",
    "\n",
    "Now take the second point on the line. Do the same as above. Increment the values ​​in the cells corresponding to ($\\rho, \\theta$) you have. This time, cell (50.90) = 2. What you actually do is vote on the ($\\rho, \\theta$) values. You continue this process for all points on the line. At each point, the cell (50,90) will be incremented or voted on, while other cells may or may not be voted. This way, in the end, the cell (50.90) will have maximum votes. So if you look in the accumulator for maximum votes, you get the value (50.90) that says there is a line in this image at distance 50 from the origin and at an angle of 90 degrees. It is well shown in the animation below (Image Courtesy: Amos Storkey )\n",
    "\n",
    "![alt text](https://docs.opencv.org/3.0-beta/_images/houghlinesdemo.gif \"Logo Title Text 1\")\n",
    "\n",
    "[logo]: https://docs.opencv.org/3.0-beta/_images/houghlinesdemo.gif \"Logo Title Text 2\"\n",
    "\n",
    "This is how the line transformer works. It's simple and you may be able to implement it using Numpy yourself. Below is an image showing the accumulator. Bright spots in some places indicate that they are the parameters of possible lines in the image. (Image courtesy of: Wikipedia)\n",
    "\n",
    "![alt text](https://docs.opencv.org/3.0-beta/_images/houghlines2.jpg \"Logo Title Text 1\")\n",
    "\n",
    "[logo]: https://docs.opencv.org/3.0-beta/_images/houghlines2.jpg \"Logo Title Text 2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and reading the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('road.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to grayscale and applying canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 70, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hough transformation takes a lot of computation. The Probabilistic Hough Transformation is an optimization of the Hough Transformation that was discussed in class.\n",
    "\n",
    "This function does not take all points into account, instead it only takes a random subset of points and this is sufficient for line detection.\n",
    "\n",
    "FUCTION **HoughLinesP(img, ρ, θ, minVal, maxVal)**\n",
    "\n",
    "Input:\n",
    "         1. img = Image we want to work with binary.\n",
    "         2. ρ = perpendicular distance from the origin to the line.\n",
    "         3. θ = perpendicular angle from line to axis.\n",
    "         4. minVal = minimum line length. Line segments shorter than this are rejected.\n",
    "         5. maxVal = maximum line length.\n",
    "Exit:\n",
    "\n",
    "         1. Image with detected edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 10, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the detected lines\n",
    "\n",
    "FUNCTION **line(img, coord1, coord2, cor, lag)**\n",
    "\n",
    "Input:\n",
    "         1. img = Image we want to work with binary.\n",
    "         2. coordinate1 = initial coordinates.\n",
    "         3. coordinate2 = final coordinates.\n",
    "         4. color = thread color.\n",
    "         5. lag = line thickness.\n",
    "Exit:\n",
    "\n",
    "         1. drawn line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1,y1),(x2,y2), (0,255,0),3)\n",
    "    \n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
