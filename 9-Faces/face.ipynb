{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "\n",
    "## Haar Classifier\n",
    "\n",
    "For face detection using the Haar classifier, you need to calculate the sums of many different rectangular regions within the image. By doing this the computational effort is great.\n",
    "\n",
    "To build a system in real time, one cannot spend as many cycles computing these sums. So something called integral images is used.\n",
    "\n",
    "![alt text](https://www.codeproject.com/KB/audio-video/haar_detection/intimage.png \"Logo Title Text 1\")\n",
    "\n",
    "[logo]: https://www.codeproject.com/KB/audio-video/haar_detection/intimage.png \"Logo Title Text 2\"\n",
    "\n",
    "To calculate the sum of any rectangle in the image, you don't need to go through all the elements in that rectangular area. Let's say the AP indicates the sum of all elements in the rectangle formed by the upper left point and the point P in the image as the two diagonally opposite corners. So, now, to calculate the area of ​​the rectangle ABCD, you can use the following formula:\n",
    "\n",
    "$ABCD = AC - (AB + AD - AA)$\n",
    "\n",
    "Why is this specific formula important? As discussed in the previous lecture, when using the Haar classifier and extracting features from the image, computing the areas of a large number of rectangles in the image is done at multiple scales.\n",
    "\n",
    "Many of these calculations are repetitive and the overall process is very slow. In fact, it's so slow you can't run anything in real time. That's the reason we use this formulation!\n",
    "\n",
    "The good thing about this approach is that it doesn't need to recalculate any instances of the image. All values ​​for the areas on the right side of this equation are already available. So it's just used to calculate the area of ​​any new rectangle and extract the features.\n",
    "\n",
    "Importing Haar Libraries and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a classifier model that can be used to detect faces in an image. OpenCV\n",
    "provides an xml file that can be used for this purpose. We use the function\n",
    "CascadeClassifier to load the xml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haar Sorters\n",
    "face_cascade = cv2.CascadeClassifier('C:/opencv/build/etc/haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we start capturing the input frames from the webcam, we convert them to grayscale and use the **detectMultiScale** function to get bounding boxes for all faces in the current image.\n",
    "\n",
    "FUNCTION **detectMultiscale (scalefactor , minNeighbors )**\n",
    "\n",
    "Input:\n",
    "         1. scalefactor = Parameter that specifies how much the image size is reduced at each image scale.\n",
    "         2. minNeighbors = Parameter that specifies how many neighbors each candidate rectangle must have to retain it.\n",
    "\n",
    "Exit:\n",
    "         1. rectangle with coordinates (x, y, w, h) around the detected face.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #Initiates a video capture with pc webcam\n",
    "\n",
    "while True:\n",
    "     ret, img = cap.read()\n",
    "\n",
    "     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "     faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "     for (x,y,w,h) in faces:\n",
    "         cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "         roi_gray = gray[y:y+h, x:x+w]\n",
    "         roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "     cv2.imshow('Face detected', img)\n",
    "\n",
    "     k = cv2.waitKey(30) & 0xff\n",
    "     if k == 27:\n",
    "         break;\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
